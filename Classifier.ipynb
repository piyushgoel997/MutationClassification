{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyPNyb19uVXKJ7axsBDSgRFO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/piyushgoel997/MutationClassification/blob/master/Classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FOzwEXPuzGBD",
        "colab_type": "text"
      },
      "source": [
        "Import statements and declaring some global variables\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBWod3zZyoBH",
        "colab_type": "code",
        "outputId": "b90ae26c-8916-4354-e762-0c26ae5f98ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "import time\n",
        "import random\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.utils import plot_model\n",
        "from sklearn.metrics import roc_curve, auc, precision_recall_curve, accuracy_score\n",
        "from tensorflow.python.keras import Sequential\n",
        "from tensorflow.python.keras.layers import Conv1D, BatchNormalization, GlobalMaxPooling1D\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "data_url = \"https://raw.githubusercontent.com/piyushgoel997/MutationClassification/master/data.csv\"\n",
        "epochs = 1000\n",
        "batch_size = 8192\n",
        "\n",
        "# to stop the model from overfitting on the training data.\n",
        "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=20, verbose=2, mode=\"min\", restore_best_weights=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n",
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PxK7n8P1zIeK",
        "colab_type": "text"
      },
      "source": [
        "Load and represent data in a one-hot encoded matrix form to be easily able to train the model.\n",
        "\n",
        "Matrix Dimentions: Number of examples, Number of Features (in this case, the length of the sequence of Amino Acids), Number of possible feature values (20 possible Amino Acids)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQHkMtSyzNG-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_aa_encoder():\n",
        "    \"\"\"\n",
        "    One-hot encoding indices for the 20 possible amino acids.\n",
        "    :return: the dictionary mapping amino acid to index in the one-hot encoding.\n",
        "    \"\"\"\n",
        "    acids = \"ARNDCEQGHILKMFPSTWYV\"\n",
        "    indices = {}\n",
        "    i = 0\n",
        "    for a in acids:\n",
        "        indices[a] = i\n",
        "        i += 1\n",
        "    return indices\n",
        "\n",
        "\n",
        "def make_matrix(seq, alt):\n",
        "    \"\"\"\n",
        "    makes a matrix where each of the 51 features correspond to the amino acid at\n",
        "    that position in the sequence after the one-hot encoding using the indices\n",
        "    provided. Also puts a -1 at in the middle most feature at the position\n",
        "    corresponding to the alt amino acid.\n",
        "    :param seq: the sequence to be encoded.\n",
        "    :param alt: the alternate amino acid\n",
        "    :return: the resultant encoded matrix (51 X 20)\n",
        "    \"\"\"\n",
        "    indices = get_aa_encoder()\n",
        "    matrix = np.zeros((len(indices), len(seq)))\n",
        "    i = 0\n",
        "    for s in seq:\n",
        "        matrix[indices[s]][i] = 1\n",
        "        i += 1\n",
        "    matrix[indices[alt]][int(len(seq) / 2)] = -1\n",
        "    return matrix.T\n",
        "\n",
        "\n",
        "def map_description(description):\n",
        "    map = {'Benign': 0, 'Benign/Likely benign': 0, 'Likely benign': 0,\n",
        "           'Likely pathogenic': 1, 'Pathogenic': 1, 'Pathogenic/Likely pathogenic': 1}\n",
        "    return map[description]\n",
        "\n",
        "\n",
        "def shuffle_together(arrays):\n",
        "    ind = list(range(len(arrays[0])))\n",
        "    random.shuffle(ind)\n",
        "    return [X[ind] for X in arrays]\n",
        "\n",
        "\n",
        "X = []\n",
        "Y = []\n",
        "gene_ids = []\n",
        "mutations = pd.read_csv(data_url)\n",
        "\n",
        "for _, row in mutations.iterrows():\n",
        "    X.append(make_matrix(row[\"REF_SEQ\"], row[\"ALT_AA\"]))\n",
        "    Y.append(map_description(row[\"DESCRIPTION\"]))\n",
        "    gene_ids.append(row[\"UNIPROT_ACCESSION\"])\n",
        "\n",
        "X = np.array(X)\n",
        "Y = np.array(Y)\n",
        "\n",
        "X, Y, gene_ids = shuffle_together([X, Y, np.array(gene_ids)])\n",
        "gene_ids = list(gene_ids)\n",
        "\n",
        "print(\"Input shape\", X.shape, \"\\nOutput shape\", Y.shape)\n",
        "print(\"Count of Pathogenic examples\", np.count_nonzero(Y == 1))\n",
        "print(\"Count of Benign examples\", np.count_nonzero(Y == 0))\n",
        "print(\"Total number of genes present\", len(set(gene_ids)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7yR-p8jB54Wh",
        "colab_type": "text"
      },
      "source": [
        "Helper methods to be initialize and comple the model, and provide different evaluation metrics like accuracy, loss, ROC curve, ROC AUC, PRC curve, etc."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahtF-2ROA2Jo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_model(h=0):\n",
        "    \"\"\"\n",
        "    make, compile and return the model\n",
        "    :param h: The number of hidden layers with 64 channels to be added\n",
        "    :return: the model\n",
        "    \"\"\"\n",
        "    model = Sequential()\n",
        "    model.add(Conv1D(32, kernel_size=3, activation=\"relu\"))\n",
        "    for _ in range(h):\n",
        "        model.add(Conv1D(64, kernel_size=5, activation=\"relu\"))\n",
        "        model.add(BatchNormalization())\n",
        "    model.add(Conv1D(32, kernel_size=3, activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Conv1D(1, kernel_size=1, activation='sigmoid'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(GlobalMaxPooling1D())\n",
        "    model.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "\n",
        "def get_model2(h):\n",
        "    \"\"\"\n",
        "    make, compile and return the model. Incresed the kernel size.\n",
        "    :param h: The number of hidden layers with 64 channels to be added\n",
        "    :return: the model\n",
        "    \"\"\"\n",
        "    model = Sequential()\n",
        "    model.add(Conv1D(32, kernel_size=5, activation=\"relu\"))\n",
        "    for _ in range(h):\n",
        "        model.add(Conv1D(64, kernel_size=7, activation=\"relu\"))\n",
        "        model.add(BatchNormalization())\n",
        "    model.add(Conv1D(32, kernel_size=5, activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Conv1D(1, kernel_size=1, activation='sigmoid'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(GlobalMaxPooling1D())\n",
        "    model.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "\n",
        "def k_fold_cross_validation(h, X, Y, k=10, epochs=20, batch_size=512, callbacks=None, get_model=get_model):\n",
        "    \"\"\"\n",
        "    Make the model, train it, and validate it using k-fold cross validation.\n",
        "    :param h: The number of hidden layers with 64 channels to be added in the model.\n",
        "    :param X: input to the model.\n",
        "    :param Y: expected outputs of the model.\n",
        "    :return: average accuracy, avg auc, k roc curve coordinates, k prc curve coordinates.\n",
        "    \"\"\"\n",
        "    avg_accuracy_tain = 0\n",
        "    avg_accuracy_val = 0\n",
        "    avg_loss_train = 0\n",
        "    avg_loss_val = 0\n",
        "    avg_roc_auc = 0\n",
        "    roc_curves = []\n",
        "    prc_curves = []\n",
        "    summary = []\n",
        "    results = \"\"\n",
        "    for i in range(k):\n",
        "        model = get_model(h)\n",
        "        print(\"========Cross Validation:\", str(i + 1) + \"/\" + str(k) + \"========\")\n",
        "        start = int(X.shape[0] * (i / k))\n",
        "        end = int(X.shape[0] * ((i + 1) / k))\n",
        "        test_data = X[start:end]\n",
        "        y_test = Y[start:end]\n",
        "        train_data = np.concatenate([X[:start], X[end:]])\n",
        "        y_train = np.concatenate([Y[:start], Y[end:]])\n",
        "        history = model.fit(train_data, y_train, validation_data=(test_data, y_test), callbacks=callbacks, batch_size=batch_size, epochs=epochs, verbose=2)\n",
        "        test_out = model.predict(test_data)\n",
        "        if results == \"\":\n",
        "            results = test_out\n",
        "        else:\n",
        "            results = np.concatenate([results, test_out])\n",
        "        fpr, tpr, _ = roc_curve(y_test, test_out)\n",
        "        roc_curves.append((fpr, tpr))\n",
        "        avg_roc_auc += auc(fpr, tpr)\n",
        "        p, r, _ = precision_recall_curve(y_test, test_out)\n",
        "        prc_curves.append((r, p))\n",
        "        avg_accuracy_tain += history.history['accuracy'][-1]\n",
        "        avg_accuracy_val += history.history['val_accuracy'][-1]\n",
        "        avg_loss_train += history.history['loss'][-1]\n",
        "        avg_loss_val += history.history['val_loss'][-1]\n",
        "        \n",
        "        if len(summary) == 0: model.summary(print_fn=lambda x: summary.append(x))\n",
        "\n",
        "        del model\n",
        "\n",
        "    return {\"avg_accuracy_train\": avg_accuracy_tain / k, \"avg_accuracy_val\": avg_accuracy_val / k,\n",
        "            \"avg_loss_train\": avg_loss_train / k, \"avg_loss_val\": avg_loss_val / k,\n",
        "            \"avg_roc_auc\": avg_roc_auc / k, \"roc\": roc_curves, \"prc\": prc_curves,\n",
        "            \"model_summary\": \"\\n\".join(summary), \"predictions\": results}\n",
        "\n",
        "\n",
        "def genes_with_both(gene_ids, Y, pred):\n",
        "    \"\"\"\n",
        "    Gets the accuracy of the predictions on genes containing both pathogenic and benign mutations.\n",
        "    Also the number of genes conatining both, and the number of examples belonging to those genes.\n",
        "    :param gene_ids: list conataining the ids of genes.\n",
        "    :param Y: 1D array or list contating the true outputs.\n",
        "    :param pred: 1D array or list contating the prediction made by the model.\n",
        "    :return: a dictionary containing all the measures.\n",
        "    \"\"\"\n",
        "    patho = set()\n",
        "    benign = set()\n",
        "    for i in range(len(gene_ids)):\n",
        "        if Y[i] == 1:\n",
        "            patho.add(gene_ids[i])\n",
        "        else:\n",
        "            benign.add(gene_ids[i])\n",
        "    intersec = patho.intersection(benign)\n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "    for y, y_, id in zip(Y, pred, gene_ids):\n",
        "        if id in intersec:\n",
        "            y_true.append(y)\n",
        "            y_pred.append(y_)\n",
        "    return {\"Accuracy\": accuracy_score(y_true, [round(p[0]) for p in y_pred]), \"patho_ct\": sum(y_true) ,\"total\": len(y_true), \"genes_with_both\": len(intersec)}\n",
        "\n",
        "\n",
        "def draw_pdf(Y, pred):\n",
        "    \"\"\"\n",
        "    Draws pdf of both the classes based on the model predictions.\n",
        "    :param Y: 1D array or list contating the true outputs.\n",
        "    :param pred: 1D array or list contating the prediction made by the model.\n",
        "    \"\"\"\n",
        "    patho = []\n",
        "    benign = []\n",
        "    for y, y_ in zip(Y, pred):\n",
        "        if y == 1:\n",
        "            patho.append(y_)\n",
        "        else:\n",
        "          benign.append(y_)\n",
        "    sns.distplot(benign,hist = False, kde=True, kde_kws = {\"shade\": True, \"linewidth\": 3}, label=\"Benign, Y=0\")\n",
        "    sns.distplot(patho,hist = False, kde=True, kde_kws = {\"shade\": True, \"linewidth\": 3}, label=\"Pathogenic, Y=1\")\n",
        "    plt.show()\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T3dqV79ns9ap",
        "colab_type": "text"
      },
      "source": [
        "Training and evaluating a few different models (with different number of hidden layers) and chosing the best one."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ejkc1dBeEr5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# best_h_acc = -1  # best h value when chosen based on the validation accuracy.\n",
        "# best_acc = 0\n",
        "best_h_auc = -1  # best h value when chosen based on the validation auc value.\n",
        "best_auc = 0\n",
        "best_pred = \"\"\n",
        "best_model_maker = get_model\n",
        "\n",
        "over_all_start_time = time.time()\n",
        "\n",
        "for h in [1, 2, 4]:\n",
        "    for model_maker in [get_model, get_model2]:\n",
        "        start_time = time.time()\n",
        "        print(\"==========Starting for h =\", str(h) + \"==========\")\n",
        "\n",
        "        metrics = k_fold_cross_validation(h, X, Y, k=5, epochs=epochs, batch_size=batch_size, callbacks=[early_stopping_callback], get_model=model_maker)\n",
        "\n",
        "        print(metrics[\"model_summary\"])\n",
        "\n",
        "        print(\"Final metrics for this model\")\n",
        "        print(\"Average of the final training set accuracy over all folds =\", str(metrics[\"avg_accuracy_train\"]))\n",
        "        print(\"Average of the final training set loss over all folds =\", str(metrics[\"avg_loss_train\"]))\n",
        "        print(\"Average of the final validation set accuracy over all folds =\", str(metrics[\"avg_accuracy_val\"]))\n",
        "        print(\"Average of the final validation set loss over all folds =\", str(metrics[\"avg_loss_val\"]))\n",
        "        print(\"Average of the ROC AUC over all folds =\", str(metrics[\"avg_roc_auc\"]))\n",
        "        pred = metrics[\"predictions\"]\n",
        "        print(\"Genes with both pathogenic and benign mutations:\")\n",
        "        print(genes_with_both(gene_ids, Y, pred))\n",
        "        draw_pdf(Y, pred)\n",
        "\n",
        "        for c in metrics[\"roc\"]: plt.plot(*c)\n",
        "        plt.xlabel('False positive rate')\n",
        "        plt.ylabel('True positive rate')\n",
        "        plt.title('ROC curve')\n",
        "        plt.show()\n",
        "\n",
        "        for c in metrics[\"prc\"]: plt.plot(*c)\n",
        "        plt.xlabel('Recall')\n",
        "        plt.ylabel('Precision')\n",
        "        plt.title('PRC curve')\n",
        "        plt.show()\n",
        "\n",
        "        # if metrics[\"avg_accuracy_val\"] > best_acc:\n",
        "        #     best_h_acc = h\n",
        "        #     best_acc = metrics[\"avg_accuracy_val\"]\n",
        "\n",
        "        if metrics[\"avg_roc_auc\"] > best_auc:\n",
        "            best_h_auc = h\n",
        "            best_auc = metrics[\"avg_roc_auc\"]\n",
        "            best_pred = pred\n",
        "            best_model_maker = model_maker\n",
        "\n",
        "        print(\"Time taken for this model\", str(time.time() - start_time))\n",
        "\n",
        "        print(\"===============Finished===============\")\n",
        "\n",
        "print(\"Total time taken\", str(time.time() - over_all_start_time))\n",
        "print(\"The h value for the best validation accuracy is\", str(best_h_acc), \"and the corresponding accuracy is\",\n",
        "      str(best_acc))\n",
        "print(\"The h value for the best auc is\", str(best_h_auc), \"and the corresponding auc is\", str(best_auc))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "97gO4DUctKCR",
        "colab_type": "text"
      },
      "source": [
        "Now training the best model architecture using the whole data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Pe2Lwo6ofTs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = best_model_maker(best_h_auc)\n",
        "history = model.fit(X, Y, batch_size=batch_size, epochs=epochs)\n",
        "\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.show()\n",
        "\n",
        "plot_model(model, to_file='model.png')\n",
        "model.summary()\n",
        "model.save(\"model.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}